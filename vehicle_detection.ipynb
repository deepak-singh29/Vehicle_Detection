{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Get Spatial binning return 32*32 features\n",
    "#----------------------------------------------\n",
    "\n",
    "def spatial_bin_feat(img,color_space = 'RGB',size = (32,32)):\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_img = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_img = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "            feature_img = feature_img[:,:,1]\n",
    "#             plt.title(feature_img[:,:,1].shape)\n",
    "#             plt.imshow(feature_img[:,:,1],cmap = 'gray')\n",
    "    else:\n",
    "        feature_img = np.copy(img)\n",
    "#     print(feature_img.shape)\n",
    "    features = cv2.resize(feature_img,size).ravel()\n",
    "   # print(features.shape)\n",
    "    return features\n",
    "\n",
    "#----------------------------------------------\n",
    "# Get Color histogram features\n",
    "#----------------------------------------------\n",
    "def color_hist(img,nbins =32,bins_range = (0,256)):\n",
    "    # histogram if RGB channels\n",
    "    rhist = np.histogram(img[:,:,0],bins = nbins,range = bins_range)\n",
    "    ghist = np.histogram(img[:,:,1],bins = nbins,range = bins_range)\n",
    "    bhist = np.histogram(img[:,:,2],bins = nbins,range = bins_range)\n",
    "    \n",
    "    h_features = np.concatenate((rhist[0],ghist[0],bhist[0]))\n",
    "    return h_features\n",
    "\n",
    "#----------------------------------------------\n",
    "# Get HOG features\n",
    "#----------------------------------------------\n",
    "def hog_features(img,orient,pix_per_cell,cell_per_block,vis = False ,feature_vec = True):\n",
    "    ret_list = hog(img,orientations = orient ,pixels_per_cell = (pix_per_cell,pix_per_cell),cells_per_block = (cell_per_block,cell_per_block),block_norm= 'L2-Hys', transform_sqrt=False, visualise= vis, feature_vector= feature_vec)\n",
    "    # name returns explicitly\n",
    "    hog_features = ret_list[0]\n",
    "    if vis:\n",
    "        hog_image = ret_list[1]\n",
    "        return hog_features.ravel(), hog_image\n",
    "    else:\n",
    "        return hog_features.ravel()\n",
    "    \n",
    "#----------------------------------------------\n",
    "# Get Combined features\n",
    "#----------------------------------------------\n",
    "def get_all_features(t_img):\n",
    "    sb_features = spatial_bin_feat(t_img,'HLS')\n",
    "    # print(sb_features.size)# 1024\n",
    "    hist_features = color_hist(t_img)\n",
    "    # print(hist_features.size) # 96\n",
    "    gray = cv2.cvtColor(t_img,cv2.COLOR_RGB2GRAY)\n",
    "    h_features, hog_image = hog_features(gray, orient= 9, \n",
    "                            pix_per_cell= 8, cell_per_block= 2, \n",
    "                            vis=True, feature_vec=False)\n",
    "\n",
    "    # print(hog_features.size) #1764\n",
    "    # print(hog_features.shape) #(1764,)\n",
    "    comb_feature = np.concatenate((sb_features,hist_features,h_features))\n",
    "#     print(comb_feature)\n",
    "    return comb_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_vehicle_paths = [\"non-vehicles/Extras/*.png\", \"non-vehicles/GTI/*.png\"]\n",
    "\n",
    "vehicle_paths = [\"vehicles/GTI_Far/*.png\", \"vehicles/GTI_Left/*.png\", \"vehicles/GTI_Right/*.png\",\n",
    "                    \"vehicles/GTI_MiddleClose/*.png\", \"vehicles/KITTI_extracted/*.png\"]\n",
    "\n",
    "non_vehicle_filenames = []\n",
    "vehicle_filenames = []\n",
    "\n",
    "for path in non_vehicle_paths:\n",
    "    non_vehicle_filenames += glob.glob(path)\n",
    "    \n",
    "for path in vehicle_paths:\n",
    "    vehicle_filenames += glob.glob(path)\n",
    "    \n",
    "# print(non_vehicle_filenames[0])\n",
    "# print(vehicle_filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"#Vehicles :\",len(vehicle_filenames),\"#Non-Vehicles:\",len(non_vehicle_filenames))\n",
    "# ## #Vehicles : 8792 #Non-Vehicles: 8968\n",
    "\n",
    "# nv_img = plt.imread(non_vehicle_filenames[10])\n",
    "# v_img = plt.imread(vehicle_filenames[10])\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.title(\"Non vehicle\")\n",
    "# plt.imshow(nv_img)\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.title(\"Vehicle\")\n",
    "# plt.imshow(v_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "17760\n"
     ]
    }
   ],
   "source": [
    "# print(np.max(nv_img),np.min(nv_img)) #0.8117647 0.015686275\n",
    "# print(v_img.shape) #(64, 64, 3)\n",
    "all_img_features = []\n",
    "for idx in range(len(vehicle_filenames)):\n",
    "    # to get all the feature\n",
    "    v_img = plt.imread(vehicle_filenames[idx])\n",
    "    img_feature = get_all_features(v_img)\n",
    "    img_feature = img_feature.tolist()\n",
    "    all_img_features.append(img_feature)\n",
    "# print(all_img_features.size)\n",
    "print(len(all_img_features))\n",
    "\n",
    "for nv_idx in range(len(non_vehicle_filenames)):\n",
    "    # to get all the feature\n",
    "    nv_img = plt.imread(non_vehicle_filenames[nv_idx])\n",
    "    img_feature = get_all_features(nv_img)\n",
    "    img_feature = img_feature.tolist()\n",
    "    all_img_features.append(img_feature)\n",
    "    \n",
    "# one hot encoded vectors is_car = 1 if its a car\n",
    "is_car = np.ones(len(vehicle_filenames))\n",
    "is_car = is_car.tolist()\n",
    "# print(len(is_car))\n",
    "non_car = np.zeros(len(non_vehicle_filenames))\n",
    "non_car = non_car.tolist()\n",
    "is_car += non_car\n",
    "print(len(is_car))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing feature vectors in pickle file\n",
    "import pickle\n",
    "output_f = open('features.pkl','wb')\n",
    "output_h = open('onehot.pkl','wb')\n",
    "pickle.dump(all_img_features,output_f)\n",
    "pickle.dump(is_car,output_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_file = open('features.pkl','rb')\n",
    "h_file = open('onehot.pkl','rb')\n",
    "X_pkl = pickle.load(f_file)\n",
    "Y_pkl = pickle.load(h_file)\n",
    "# print(len(X_train)) #17760\n",
    "# print(len(Y_train)) #17760\n",
    "X = np.vstack(X_pkl).astype(np.float64)\n",
    "y = np.hstack(Y_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----------------------------\n",
    "# Training the SVN model\n",
    "#-----------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "rand_state = np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = rand_state)\n",
    "\n",
    "# fit a per column scalar\n",
    "X_scalar = StandardScaler().fit(X_train)\n",
    "#Apply the scalar  to X\n",
    "scaled_X_train = X_scalar.transform(X_train)\n",
    "scaled_X_test = X_scalar.transform(X_test)\n",
    "#print(scaled_X_test)\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(scaled_X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9985923423423423\n",
      "Test Accuracy : 0.9293355855855856\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy :\",svc.score(scaled_X_train,y_train))\n",
    "# Train Accuracy : 0.9985923423423423\n",
    "print(\"Test Accuracy :\",svc.score(scaled_X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1,23,44])\n",
    "# a = a.tolist()\n",
    "# print(type(a))\n",
    "# x = []\n",
    "# t = [1,2]\n",
    "# p = [1,3]\n",
    "# x.append(t)\n",
    "# x.append(p)\n",
    "# print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
